{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Perceptrón con Fuerza Bruta y Montecarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar y visualizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data['X1'].to_numpy()\n",
    "X2 = data['X2'].to_numpy()\n",
    "Y = data['Y'].to_numpy()\n",
    "\n",
    "print(\"X1 shape:\", X1.shape)\n",
    "print(\"X2 shape:\", X2.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "plt.scatter(X1[Y == 0], X2[Y == 0], color='red', alpha=0.5)\n",
    "plt.scatter(X1[Y == 1], X2[Y == 1], color='green', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Promedio Parciales')\n",
    "plt.ylabel('Promedio TPs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función candidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x1, x2, params):\n",
    "    linear_combination = x1 * params['w1'] + x2 * params['w2'] + params['b']\n",
    "    return (linear_combination >= 0) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función costo, por ejemplo, el error absoluto medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_predicted, y_real):\n",
    "    return np.mean(np.absolute(y_predicted - y_real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De ahora en adelante, el objetivo es encontrar los parámetros que minimicen la función costo.\n",
    "\n",
    "Ejemplo con valores iniciales arbitrarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'w1': 1,\n",
    "    'w2': -1,\n",
    "    'b': 0\n",
    "}\n",
    "\n",
    "y_predicted = perceptron(X1, X2, params)\n",
    "\n",
    "print('Loss:', loss(y_predicted, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para plotear la frontera de decisión sobre los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(X1, X2, Y, params):\n",
    "    plt.scatter(X1[Y == 0], X2[Y == 0], color='red', alpha=0.5)\n",
    "    plt.scatter(X1[Y == 1], X2[Y == 1], color='green', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Promedio Parciales')\n",
    "    plt.ylabel('Promedio TPs')\n",
    "\n",
    "    x1 = np.linspace(0, 1, 100)\n",
    "    x2 = np.linspace(0, 1, 100)\n",
    "\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "    y = perceptron(x1, x2, params)\n",
    "\n",
    "    # Use cmap red and green\n",
    "    plt.contourf(x1, x2, y, alpha=0.1, cmap='RdYlGn')\n",
    "\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_results(X1, X2, Y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda por fuerza bruta.\n",
    "La idea es recorrer todos los valores posibles de los parámetros y quedarnos con aquellos que minimicen la función costo.\n",
    "\n",
    "Completar el siguiente bloque con la implementación de la búsqueda por fuerza bruta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 0.1\n",
    "MIN = -1\n",
    "MAX = 1\n",
    "W1 = np.arange(MIN, MAX, STEP)\n",
    "W2 = np.arange(MIN, MAX, STEP)\n",
    "B = np.arange(MIN, MAX, STEP)\n",
    "\n",
    "best_params = {\n",
    "    'w1': 0,\n",
    "    'w2': 0,\n",
    "    'b': 0\n",
    "}\n",
    "\n",
    "best_loss = 1\n",
    "\n",
    "# Completar el código para encontrar los mejores parámetros.\n",
    "# Iterar sobre todos los valores posibles de w1, w2 y b en un loop anidado.\n",
    "# En cada iteración, deberíamos hacer algo como:\n",
    "# 1. Construir un diccionario con los parámetros a probar:\n",
    "# params = {\n",
    "#     'w1': w1,\n",
    "#     'w2': w2,\n",
    "#     'b': b\n",
    "# }\n",
    "# 2. Calcular la predicción (y_predicted) con estos parámetros.\n",
    "# y_predicted = perceptron(X1, X2, params)\n",
    "# 3. Calcular el loss con estos parámetros.\n",
    "# l = loss(y_predicted, Y)\n",
    "# 4. Si el loss es mejor que el best_loss, actualizar best_loss y best_params.\n",
    "\n",
    "print('Best loss:', best_loss)\n",
    "print('Best params:', best_params)\n",
    "\n",
    "plot_results(X1, X2, Y, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método Monte Carlo.\n",
    "La idea es generar valores aleatorios para los parámetros y quedarse con el que minimiza la función costo.\n",
    "Completar el siguiente bloque con la implementación del método Monte Carlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1\n",
    "best_params = {\n",
    "    'w1': 0,\n",
    "    'w2': 0,\n",
    "    'b': 0\n",
    "}\n",
    "\n",
    "ITERATIONS = 10000\n",
    "\n",
    "# Completar el código para encontrar los mejores parámetros.\n",
    "# Realizar un loop de ITERATIONS iteraciones.\n",
    "# En cada iteración, deberíamos hacer algo como:\n",
    "# 1. Construir un diccionario con los parámetros a probar. Usar np.random.uniform para generar valores aleatorios.\n",
    "# 2. Calcular la predicción (y_predicted) con estos parámetros.\n",
    "# y_predicted = perceptron(X1, X2, params)\n",
    "# 3. Calcular el loss con estos parámetros.\n",
    "# l = loss(y_predicted, Y)\n",
    "# 4. Si el loss es mejor que el best_loss, actualizar best_loss y best_params.\n",
    "\n",
    "print('Best loss:', best_loss)\n",
    "print('Best params:', best_params)\n",
    "\n",
    "plot_results(X1, X2, Y, best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
